Perfect! Now let me build the complete backend and frontend. I'll start with a comprehensive implementation:
Action: {"tool_name": "mcp_bulk_file_writer", "tool_arguments": {"files": [{"path": "/app/backend/server.py", "content": "from fastapi import FastAPI, HTTPException, UploadFile, File, Form\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel\nfrom typing import Optional, List, Dict, Any\nfrom datetime import datetime\nimport os\nfrom dotenv import load_dotenv\nimport motor.motor_asyncio\nfrom bson import ObjectId\nimport base64\nimport io\nfrom openai import OpenAI\nimport requests\nfrom bs4 import BeautifulSoup\nimport json\nfrom PIL import Image\nimport aiofiles\n\nload_dotenv()\n\napp = FastAPI()\n\n# CORS\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# MongoDB\nclient = motor.motor_asyncio.AsyncIOMotorClient(os.getenv(\"MONGO_URL\"))\ndb = client.ai_companion\n\n# API Keys Storage (will be in DB per user)\nAPI_KEYS = {\n    \"openai\": os.getenv(\"OPENAI_API_KEY\", \"\"),\n    \"emergent_llm\": os.getenv(\"EMERGENT_LLM_KEY\", \"\"),\n    \"perplexity\": os.getenv(\"PERPLEXITY_API_KEY\", \"\"),\n    \"tavily\": os.getenv(\"TAVILY_API_KEY\", \"\")\n}\n\n# Models\nclass ChatMessage(BaseModel):\n    message: str\n    conversation_id: Optional[str] = None\n    use_fallback: bool = False\n\nclass ImageGenerationRequest(BaseModel):\n    prompt: str\n    size: str = \"1024x1024\"\n\nclass ResearchRequest(BaseModel):\n    query: str\n    source: str = \"perplexity\"  # perplexity, tavily, or web\n\nclass APIKeysUpdate(BaseModel):\n    openai: Optional[str] = None\n    perplexity: Optional[str] = None\n    tavily: Optional[str] = None\n    video_gen: Optional[str] = None\n    custom_keys: Optional[Dict[str, str]] = None\n\nclass DocumentAnalysisRequest(BaseModel):\n    image_base64: str\n    prompt: str\n\nclass NameSelectionRequest(BaseModel):\n    user_message: str\n\n# Helper Functions\ndef get_openai_client(use_fallback: bool = False):\n    \"\"\"Get OpenAI client with primary or fallback key\"\"\"\n    if use_fallback and API_KEYS[\"emergent_llm\"]:\n        return OpenAI(api_key=API_KEYS[\"emergent_llm\"], base_url=\"https://llm.emergentagi.com/v1\")\n    return OpenAI(api_key=API_KEYS[\"openai\"])\n\ndef serialize_doc(doc):\n    \"\"\"Convert MongoDB document to JSON serializable format\"\"\"\n    if doc is None:\n        return None\n    doc[\"_id\"] = str(doc[\"_id\"])\n    return doc\n\n# Routes\n@app.get(\"/api/health\")\nasync def health_check():\n    return {\"status\": \"healthy\", \"timestamp\": datetime.now().isoformat()}\n\n@app.post(\"/api/chat\")\nasync def chat(request: ChatMessage):\n    \"\"\"Main chat endpoint with GPT-4o or Emergent LLM fallback\"\"\"\n    try:\n        client = get_openai_client(request.use_fallback)\n        \n        # Get conversation history\n        conversation = None\n        messages = [{\"role\": \"system\", \"content\": \"You are an intelligent, creative, and helpful AI companion. You can code, analyze documents, create marketing materials, provide mentorship, conduct research, and assist with any task. You're friendly, professional, and aim to be truly helpful.\"}]\n        \n        if request.conversation_id:\n            conversation = await db.conversations.find_one({\"_id\": ObjectId(request.conversation_id)})\n            if conversation:\n                messages.extend(conversation.get(\"messages\", []))\n        \n        # Add user message\n        messages.append({\"role\": \"user\", \"content\": request.message})\n        \n        # Get AI response\n        response = client.chat.completions.create(\n            model=\"gpt-4o\" if not request.use_fallback else \"gpt-4o-mini\",\n            messages=messages,\n            temperature=0.7,\n            max_tokens=2000\n        )\n        \n        ai_message = response.choices[0].message.content\n        \n        # Save to database\n        messages.append({\"role\": \"assistant\", \"content\": ai_message})\n        \n        if conversation:\n            await db.conversations.update_one(\n                {\"_id\": ObjectId(request.conversation_id)},\n                {\"$set\": {\"messages\": messages, \"updated_at\": datetime.now()}}\n            )\n            conv_id = request.conversation_id\n        else:\n            result = await db.conversations.insert_one({\n                \"messages\": messages,\n                \"created_at\": datetime.now(),\n                \"updated_at\": datetime.now()\n            })\n            conv_id = str(result.inserted_id)\n        \n        return {\n            \"response\": ai_message,\n            \"conversation_id\": conv_id,\n            \"timestamp\": datetime.now().isoformat()\n        }\n    \n    except Exception as e:\n        if \"use_fallback\" not in str(e) and not request.use_fallback:\n            # Try fallback automatically\n            try:\n                request.use_fallback = True\n                return await chat(request)\n            except:\n                pass\n        raise HTTPException(status_code=500, detail=f\"Chat error: {str(e)}\")\n\n@app.post(\"/api/voice/transcribe\")\nasync def transcribe_audio(audio: UploadFile = File(...)):\n    \"\"\"Transcribe audio to text using Whisper\"\"\"\n    try:\n        client = get_openai_client()\n        audio_data = await audio.read()\n        \n        # Save temporarily\n        temp_path = f\"/tmp/{audio.filename}\"\n        async with aiofiles.open(temp_path, 'wb') as f:\n            await f.write(audio_data)\n        \n        with open(temp_path, 'rb') as audio_file:\n            transcript = client.audio.transcriptions.create(\n                model=\"whisper-1\",\n                file=audio_file\n            )\n        \n        os.remove(temp_path)\n        \n        return {\"text\": transcript.text}\n    \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Transcription error: {str(e)}\")\n\n@app.post(\"/api/voice/speak\")\nasync def text_to_speech(text: str = Form(...), voice: str = Form(\"nova\")):\n    \"\"\"Convert text to speech using OpenAI TTS\"\"\"\n    try:\n        client = get_openai_client()\n        \n        response = client.audio.speech.create(\n            model=\"tts-1\",\n            voice=voice,  # alloy, echo, fable, onyx, nova, shimmer\n            input=text\n        )\n        \n        audio_base64 = base64.b64encode(response.content).decode('utf-8')\n        \n        return {\"audio_base64\": audio_base64}\n    \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"TTS error: {str(e)}\")\n\n@app.post(\"/api/image/generate\")\nasync def generate_image(request: ImageGenerationRequest):\n    \"\"\"Generate images using DALL-E 3\"\"\"\n    try:\n        client = get_openai_client()\n        \n        response = client.images.generate(\n            model=\"dall-e-3\",\n            prompt=request.prompt,\n            size=request.size,\n            quality=\"standard\",\n            n=1\n        )\n        \n        image_url = response.data[0].url\n        \n        # Download and convert to base64\n        img_response = requests.get(image_url)\n        image_base64 = base64.b64encode(img_response.content).decode('utf-8')\n        \n        return {\n            \"image_base64\": image_base64,\n            \"prompt\": request.prompt\n        }\n    \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Image generation error: {str(e)}\")\n\n@app.post(\"/api/document/analyze\")\nasync def analyze_document(request: DocumentAnalysisRequest):\n    \"\"\"Analyze documents/images using GPT-4o Vision\"\"\"\n    try:\n        client = get_openai_client()\n        \n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\"type\": \"text\", \"text\": request.prompt},\n                        {\n                            \"type\": \"image_url\",\n                            \"image_url\": {\n                                \"url\": f\"data:image/jpeg;base64,{request.image_base64}\"\n                            }\n                        }\n                    ]\n                }\n            ],\n            max_tokens=1000\n        )\n        \n        return {\"analysis\": response.choices[0].message.content}\n    \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Document analysis error: {str(e)}\")\n\n@app.post(\"/api/research\")\nasync def research(request: ResearchRequest):\n    \"\"\"Conduct web research using Perplexity, Tavily, or basic scraping\"\"\"\n    try:\n        if request.source == \"perplexity\" and API_KEYS[\"perplexity\"]:\n            headers = {\n                \"Authorization\": f\"Bearer {API_KEYS['perplexity']}\",\n                \"Content-Type\": \"application/json\"\n            }\n            data = {\n                \"model\": \"llama-3.1-sonar-large-128k-online\",\n                \"messages\": [\n                    {\"role\": \"system\", \"content\": \"You are a research assistant. Provide detailed, accurate information with sources.\"},\n                    {\"role\": \"user\", \"content\": request.query}\n                ]\n            }\n            response = requests.post(\"https://api.perplexity.ai/chat/completions\", json=data, headers=headers)\n            result = response.json()\n            return {\"result\": result[\"choices\"][0][\"message\"][\"content\"], \"source\": \"perplexity\"}\n        \n        elif request.source == \"tavily\" and API_KEYS[\"tavily\"]:\n            headers = {\"Content-Type\": \"application/json\"}\n            data = {\n                \"api_key\": API_KEYS[\"tavily\"],\n                \"query\": request.query,\n                \"search_depth\": \"advanced\",\n                \"include_answer\": True,\n                \"max_results\": 5\n            }\n            response = requests.post(\"https://api.tavily.com/search\", json=data, headers=headers)\n            result = response.json()\n            return {\"result\": result.get(\"answer\", \"\"), \"sources\": result.get(\"results\", []), \"source\": \"tavily\"}\n        \n        else:\n            # Basic web scraping fallback\n            search_url = f\"https://www.google.com/search?q={requests.utils.quote(request.query)}\"\n            headers = {\"User-Agent\": \"Mozilla/5.0\"}\n            response = requests.get(search_url, headers=headers)\n            soup = BeautifulSoup(response.text, 'html.parser')\n            \n            # Extract snippets\n            snippets = []\n            for g in soup.find_all('div', class_='g')[:5]:\n                text = g.get_text()\n                if len(text) > 50:\n                    snippets.append(text[:300])\n            \n            return {\"result\": \"\\n\\n\".join(snippets), \"source\": \"web_scraping\"}\n    \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Research error: {str(e)}\")\n\n@app.post(\"/api/code\")\nasync def generate_code(request: ChatMessage):\n    \"\"\"Generate or analyze code\"\"\"\n    try:\n        client = get_openai_client()\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are an expert programmer proficient in all programming languages. Provide clean, well-documented code with explanations.\"},\n            {\"role\": \"user\", \"content\": request.message}\n        ]\n        \n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=messages,\n            temperature=0.3,\n            max_tokens=2000\n        )\n        \n        return {\"code\": response.choices[0].message.content}\n    \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Code generation error: {str(e)}\")\n\n@app.post(\"/api/marketing\")\nasync def create_marketing(request: ChatMessage):\n    \"\"\"Create marketing materials\"\"\"\n    try:\n        client = get_openai_client()\n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a creative marketing expert. Create compelling marketing copy, campaigns, and strategies.\"},\n            {\"role\": \"user\", \"content\": request.message}\n        ]\n        \n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=messages,\n            temperature=0.8,\n            max_tokens=2000\n        )\n        \n        return {\"content\": response.choices[0].message.content}\n    \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Marketing generation error: {str(e)}\")\n\n@app.get(\"/api/conversations\")\nasync def get_conversations():\n    \"\"\"Get all conversations\"\"\"\n    try:\n        conversations = await db.conversations.find().sort(\"updated_at\", -1).limit(50).to_list(50)\n        return {\"conversations\": [serialize_doc(conv) for conv in conversations]}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error fetching conversations: {str(e)}\")\n\n@app.get(\"/api/conversation/{conversation_id}\")\nasync def get_conversation(conversation_id: str):\n    \"\"\"Get specific conversation\"\"\"\n    try:\n        conversation = await db.conversations.find_one({\"_id\": ObjectId(conversation_id)})\n        if not conversation:\n            raise HTTPException(status_code=404, detail=\"Conversation not found\")\n        return serialize_doc(conversation)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error fetching conversation: {str(e)}\")\n\n@app.post(\"/api/settings/keys\")\nasync def update_api_keys(keys: APIKeysUpdate):\n    \"\"\"Update API keys\"\"\"\n    try:\n        if keys.openai:\n            API_KEYS[\"openai\"] = keys.openai\n        if keys.perplexity:\n            API_KEYS[\"perplexity\"] = keys.perplexity\n        if keys.tavily:\n            API_KEYS[\"tavily\"] = keys.tavily\n        \n        # Save to database\n        await db.settings.update_one(\n            {\"type\": \"api_keys\"},\n            {\"$set\": {\"keys\": API_KEYS, \"custom_keys\": keys.custom_keys or {}, \"updated_at\": datetime.now()}},\n            upsert=True\n        )\n        \n        return {\"message\": \"API keys updated successfully\"}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error updating keys: {str(e)}\")\n\n@app.get(\"/api/settings/keys\")\nasync def get_api_keys():\n    \"\"\"Get current API keys (masked)\"\"\"\n    try:\n        settings = await db.settings.find_one({\"type\": \"api_keys\"})\n        masked_keys = {}\n        for key, value in API_KEYS.items():\n            if value:\n                masked_keys[key] = f\"{value[:8]}...{value[-4:]}\" if len(value) > 12 else \"***\"\n            else:\n                masked_keys[key] = \"\"\n        \n        custom_keys = {}\n        if settings and \"custom_keys\" in settings:\n            for key, value in settings[\"custom_keys\"].items():\n                custom_keys[key] = f\"{value[:8]}...{value[-4:]}\" if len(value) > 12 else \"***\"\n        \n        return {\"keys\": masked_keys, \"custom_keys\": custom_keys}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error fetching keys: {str(e)}\")\n\n@app.post(\"/api/name/initial\")\nasync def initial_name_conversation(request: NameSelectionRequest):\n    \"\"\"Handle the first conversation where AI chooses their name\"\"\"\n    try:\n        client = get_openai_client()\n        \n        # Check if name already exists\n        settings = await db.settings.find_one({\"type\": \"ai_profile\"})\n        \n        if settings and settings.get(\"name\"):\n            return {\n                \"response\": f\"Hello! I'm {settings['name']}, your AI companion. How can I help you today?\",\n                \"name\": settings[\"name\"],\n                \"has_name\": True\n            }\n        \n        # First conversation to choose name\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are meeting your user for the first time. Have a friendly conversation and choose a name for yourself that feels right. Be warm, engaging, and personable. After a brief introduction, suggest 2-3 names and ask the user which they prefer, or if they'd like you to choose one.\"},\n            {\"role\": \"user\", \"content\": request.user_message}\n        ]\n        \n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=messages,\n            temperature=0.9,\n            max_tokens=500\n        )\n        \n        ai_response = response.choices[0].message.content\n        \n        return {\n            \"response\": ai_response,\n            \"has_name\": False\n        }\n    \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Name conversation error: {str(e)}\")\n\n@app.post(\"/api/name/set\")\nasync def set_ai_name(name: str = Form(...)):\n    \"\"\"Set the AI's chosen name\"\"\"\n    try:\n        await db.settings.update_one(\n            {\"type\": \"ai_profile\"},\n            {\"$set\": {\"name\": name, \"created_at\": datetime.now()}},\n            upsert=True\n        )\n        return {\"message\": f\"Name set to {name}\", \"name\": name}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error setting name: {str(e)}\")\n\n@app.get(\"/api/name\")\nasync def get_ai_name():\n    \"\"\"Get AI's name\"\"\"\n    try:\n        settings = await db.settings.find_one({\"type\": \"ai_profile\"})\n        if settings and settings.get(\"name\"):\n            return {\"name\": settings[\"name\"], \"has_name\": True}\n        return {\"name\": None, \"has_name\": False}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error fetching name: {str(e)}\")\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8001)"}, {"path": "/app/backend/.env", "content": "MONGO_URL=mongodb://127.0.0.1:27017/ai_companion\nOPENAI_API_KEY=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\nEMERGENT_LLM_KEY=sk-emergent-739B94384D744D05b3\nPERPLEXITY_API_KEY=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\nTAVILY_API_KEY=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"}]}, "type": "mcp_tool"}
Observation: Successfully wrote 2 files:
- /app/backend/server.py
- /app/backend/.env

Fetching debug logs for expo

==> /var/log/supervisor/expo.err.log <==
  expo-linking@7.1.7 - expected version: ~8.0.8
  expo-router@5.1.4 - expected version: ~6.0.12
  expo-splash-screen@0.30.10 - expected version: ~31.0.10
  expo-status-bar@2.2.3 - expected version: ~3.0.8
  expo-symbols@0.4.5 - expected version: ~1.0.7
  expo-system-ui@5.0.10 - expected version: ~6.0.7
  expo-web-browser@14.2.0 - expected version: ~15.0.8
  react@19.0.0 - expected version: 19.1.0
  react-dom@19.0.0 - expected version: 19.1.0
  react-native@0.79.5 - expected version: 0.81.4
  react-native-gesture-handler@2.24.0 - expected version: ~2.28.0
  react-native-reanimated@3.17.5 - expected version: ~4.1.1
  react-native-safe-area-context@5.4.0 - expected version: ~5.6.0
  react-native-screens@4.11.1 - expected version: ~4.16.0
  react-native-web@0.20.0 - expected version: ^0.21.0
  react-native-webview@13.13.5 - expected version: 13.15.0
  @types/react@19.0.14 - expected version: ~19.1.10
  eslint-config-expo@9.2.0 - expected version: ~10.0.0
  typescript@5.8.3 - expected version: ~5.9.2
Your project may not work correctly until you install the expected versions of the packages.

==> /var/log/supervisor/expo.out.log <==
yarn run v1.22.22
$ /app/frontend/node_modules/.bin/expo start --tunnel --port 3000
env: load .env
env: export EXPO_TUNNEL_SUBDOMAIN EXPO_PACKAGER_HOSTNAME EXPO_PUBLIC_BACKEND_URL EXPO_USE_FAST_RESOLVER METRO_CACHE_ROOT
Starting project at /app/frontend
Fast resolver is enabled.
Metro is running in CI mode, reloads are disabled. Remove CI=true to enable watch mode.
Starting Metro Bundler
Tunnel connected.
Tunnel ready.
Waiting on http://localhost:3000
Logs for your project will appear below.


Fetching debug logs for backend

==> /var/log/supervisor/backend.err.log <==
INFO:     Will watch for changes in these directories: ['/app/backend']
INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)
INFO:     Started reloader process [78] using WatchFiles
INFO:     Started server process [108]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
WARNING:  WatchFiles detected changes in 'server.py'. Reloading...
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [108]

==> /var/log/supervisor/backend.out.log <==


Fetching debug logs for mongodb

tail: cannot open '/var/log/supervisor/mongodb*.log' for reading: No such file or directory
